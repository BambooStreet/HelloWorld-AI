{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "ES_CLOUD_ID = os.getenv(\"ES_CLOUD_ID\")\n",
    "ES_USER = os.getenv(\"ES_USER\")\n",
    "ES_PASSWORD = os.getenv(\"ES_PASSWORD\")\n",
    "ES_API_KEY = os.getenv(\"ES_API_KEY\")\n",
    "index_name = \"helloworld4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Prep. Huggingface embedding setup\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "def setup_embeddings():\n",
    "    # Huggingface embedding setup\n",
    "    print(\">> Prep. Huggingface embedding setup\")\n",
    "    #model_name = \"jhgan/ko-sroberta-nli\"\n",
    "    model_name = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
    "    return HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "hf = setup_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticSearch vectorstore in langchain style\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "\n",
    "db = ElasticsearchStore(\n",
    "    es_cloud_id=ES_CLOUD_ID,\n",
    "    es_user=ES_USER,\n",
    "    es_password=ES_PASSWORD,\n",
    "    es_api_key=ES_API_KEY,\n",
    "    index_name=\"helloworld4\",\n",
    "    embedding=hf,\n",
    "    #es_url = 'https://bfc3fd6827b94a4ea8d56f9805a44cae.us-central1.gcp.cloud.es.io:443'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>법무부 외국인 체류관리</td>\n",
       "      <td>외국인 체류관리</td>\n",
       "      <td>category: 외국인 체류관리\\ntext:\\n법무부는 합법적인 이주를 장려하고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>법무부 외국인 체류관리</td>\n",
       "      <td>노동시장의 수요를 고려한 외국인유입정책</td>\n",
       "      <td>category: 노동시장의 수요를 고려한 외국인유입정책\\ntext:\\n법무부는 고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>법무부 외국인 체류관리</td>\n",
       "      <td>계절근로자 제도</td>\n",
       "      <td>category: 계절근로자 제도\\ntext:\\n농‧어촌의 고질적인 인력부족 문제를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>법무부 외국인 체류관리</td>\n",
       "      <td>외국인 숙련기능인력 점수제 비자</td>\n",
       "      <td>category: 외국인 숙련기능인력 점수제 비자\\ntext:\\n주조‧금형‧용접 등...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>법무부 외국인 체류관리</td>\n",
       "      <td>해외 우수인재 유치</td>\n",
       "      <td>category: 해외 우수인재 유치\\ntext:\\n국가경쟁력에 직결되는 우수인재‧...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         source                  title  \\\n",
       "0  법무부 외국인 체류관리               외국인 체류관리   \n",
       "1  법무부 외국인 체류관리  노동시장의 수요를 고려한 외국인유입정책   \n",
       "2  법무부 외국인 체류관리               계절근로자 제도   \n",
       "3  법무부 외국인 체류관리      외국인 숙련기능인력 점수제 비자   \n",
       "4  법무부 외국인 체류관리             해외 우수인재 유치   \n",
       "\n",
       "                                             content  \n",
       "0  category: 외국인 체류관리\\ntext:\\n법무부는 합법적인 이주를 장려하고 ...  \n",
       "1  category: 노동시장의 수요를 고려한 외국인유입정책\\ntext:\\n법무부는 고...  \n",
       "2  category: 계절근로자 제도\\ntext:\\n농‧어촌의 고질적인 인력부족 문제를...  \n",
       "3  category: 외국인 숙련기능인력 점수제 비자\\ntext:\\n주조‧금형‧용접 등...  \n",
       "4  category: 해외 우수인재 유치\\ntext:\\n국가경쟁력에 직결되는 우수인재‧...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('./data/preprocessed.csv')\n",
    "#data['text'] = ''\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3433, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size = 500,\n",
    "#     chunk_overlap  = 100,\n",
    "#     length_function = len,\n",
    "# )\n",
    "\n",
    "# #texts = text_splitter.split_text(data[0].page_content)\n",
    "# texts = text_splitter.split_text(data['content'][0])\n",
    "# len(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# LLaMA-3 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"MLP-KTLim/llama-3-Korean-Bllossom-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# RAG style : title + [SEP] + contents\n",
    "# seperation 지정되어 있지 않음 -> 공백으로 처리\n",
    "def make_chunk_data(titles: list, contents: list) -> list:\n",
    "    if tokenizer.sep_token != None:\n",
    "        print('## seperated by : ', tokenizer.sep_token)\n",
    "        chunk_data = [title + tokenizer.sep_token + content for title, content in zip(titles, contents)]\n",
    "    else:\n",
    "        chunk_data = [title + \" \" + content for title, content in zip(titles, contents)]\n",
    "    \n",
    "    return chunk_data\n",
    "\n",
    "\n",
    "# 토크나이저 기준 분할\n",
    "def data_chunking(titles: list, contents: list) -> Document:\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        tokenizer,\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    chunk_data = make_chunk_data(titles, contents)\n",
    "    chunks = text_splitter.create_documents(chunk_data)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 리스트 초기화\n",
    "titles = []\n",
    "contents = []\n",
    "\n",
    "# 데이터프레임 순회\n",
    "for index, row in data.iterrows():\n",
    "    titles.append(row['title'])\n",
    "    contents.append(row['content'])\n",
    "\n",
    "# 결과 확인\n",
    "#print(\"Titles:\", titles)\n",
    "#print(\"Contents:\", contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3433, 3433)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles), len(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = data_chunking(titles, contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6078"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # RecursiveCharacterTextSplitter 초기화\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "#     tokenizer,\n",
    "#     chunk_size=512,\n",
    "#     chunk_overlap=100\n",
    "# )\n",
    "# chunk_data = make_chunk_data(titles,conents)\n",
    "# chunks = text_splitter.create_douments(shunk_data)\n",
    "\n",
    "\n",
    "# # 새로운 DataFrame을 저장할 리스트\n",
    "# new_rows = []\n",
    "\n",
    "# # 각 행을 순회하면서 처리\n",
    "# for _, row in data.iterrows():\n",
    "#     content = row['content']\n",
    "#     chunks = text_splitter.split_text(content)\n",
    "    \n",
    "#     # 각 청크에 대해 새로운 행 생성\n",
    "#     for chunk in chunks:\n",
    "#         new_row = row.copy()  # 기존 행의 모든 데이터 복사\n",
    "#         new_row['text'] = chunk  # 'text' 열에 청크 추가\n",
    "#         new_rows.append(new_row)\n",
    "\n",
    "# # 새로운 DataFrame 생성\n",
    "# chunk_data = pd.DataFrame(new_rows)\n",
    "\n",
    "# # 'content' 열 제거 (선택사항)\n",
    "# chunk_data = chunk_data.drop(columns=['content'])\n",
    "\n",
    "# # 인덱스 재설정\n",
    "# chunk_data = chunk_data.reset_index(drop=True)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(chunk_data.head())\n",
    "# print(f\"Total rows in new DataFrame: {len(chunk_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape, chunk_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchtext = list(chunk_data['text'])\n",
    "# len(batchtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='외국인 체류관리 category: 외국인 체류관리\\ntext:\\n법무부는 합법적인 이주를 장려하고 촉진하며 지원하기 위하여 다양한 정책적 지원방안을 시행하고 있습니다.\\n2013년부터 교수/연구원 등 전문인력, 의료관광객, 단체관광객 등 일부 외국인의 경우, 재외공관을 방문하지 않고도 온라인(비자포털, www.visa.go.kr)으로 대한민국 비자를 신청/발급 받아 신속, 편리하게 입국할 수 있도록 전자비자 제도를 시행함으로써 비자신청 민원편의를 도모하고 있습니다.\\n또한 유학비자를 발급받고자 하는 학생들의 경우, 우수한 학습프로그램과 유학생 지원체계를 보유하고 있는 학교를 선택하도록 장려함으로써 우수한 외국 학생들이 한국에서 인적 자본을 성장시킬 수 있도록 지속적으로 지원하고 있습니다.'),\n",
       " Document(page_content='노동시장의 수요를 고려한 외국인유입정책 category: 노동시장의 수요를 고려한 외국인유입정책\\ntext:\\n법무부는 고용노동부, 산업통상자원부 등 관계부처와 유기적으로 협력하여 외국인근로자 정책을 수립･시행하고 있습니다.\\n농어업 부문 등 1차 산업 및 도장･금형･주조 등 기초 2차 산업의 비숙련 부문 등 인력부족을 겪고 있는 영역에서 외국 인력이 활용될 수 있도록 다양한 비자정책을 시행하고 있습니다.')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6078"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# \"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 런타임 모두 실행 시 DB에 데이터가 중복 저장되는 것을 막기 위해 주석 처리 해놨습니다.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 필요한 코드이니 지우지 말아주세요.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#꼭 확인!!\u001b[39;00m\n\u001b[0;32m      8\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhelloworld4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m              \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m              \u001b[49m\u001b[43mes_cloud_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mES_CLOUD_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m              \u001b[49m\u001b[43mes_user\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mES_USER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m              \u001b[49m\u001b[43mes_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mES_PASSWORD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m              \u001b[49m\u001b[43mes_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mES_API_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m              \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ohmyh\\OneDrive\\바탕 화면\\GitHub\\HelloWorld_data\\.venv\\lib\\site-packages\\langchain_elasticsearch\\vectorstores.py:1082\u001b[0m, in \u001b[0;36mElasticsearchStore.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, bulk_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m elasticsearchStore \u001b[38;5;241m=\u001b[39m ElasticsearchStore(embedding\u001b[38;5;241m=\u001b[39membedding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;66;03m# Encode the provided texts and add them to the newly created index.\u001b[39;00m\n\u001b[1;32m-> 1082\u001b[0m \u001b[43melasticsearchStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbulk_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbulk_kwargs\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m elasticsearchStore\n",
      "File \u001b[1;32mc:\\Users\\ohmyh\\OneDrive\\바탕 화면\\GitHub\\HelloWorld_data\\.venv\\lib\\site-packages\\langchain_elasticsearch\\vectorstores.py:978\u001b[0m, in \u001b[0;36mElasticsearchStore.add_texts\u001b[1;34m(self, texts, metadatas, ids, refresh_indices, create_index_if_not_exists, bulk_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_texts\u001b[39m(\n\u001b[0;32m    952\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    953\u001b[0m     texts: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    960\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    961\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run more texts through the embeddings and add to the store.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \n\u001b[0;32m    963\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;124;03m        List of ids from adding the texts into the store.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefresh_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_index_if_not_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_index_if_not_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbulk_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbulk_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ohmyh\\OneDrive\\바탕 화면\\GitHub\\HelloWorld_data\\.venv\\lib\\site-packages\\elasticsearch\\helpers\\vectorstore\\_sync\\vectorstore.py:131\u001b[0m, in \u001b[0;36mVectorStore.add_texts\u001b[1;34m(self, texts, metadatas, vectors, ids, refresh_indices, create_index_if_not_exists, bulk_kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_index_if_not_exists()\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_service \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vectors:\n\u001b[1;32m--> 131\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(texts):\n\u001b[0;32m    134\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m metadatas[i] \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "File \u001b[1;32mc:\\Users\\ohmyh\\OneDrive\\바탕 화면\\GitHub\\HelloWorld_data\\.venv\\lib\\site-packages\\langchain_elasticsearch\\embeddings.py:239\u001b[0m, in \u001b[0;36mEmbeddingServiceAdapter.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m    228\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m    Generate embeddings for a list of documents.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m            list.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_langchain_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ohmyh\\OneDrive\\바탕 화면\\GitHub\\HelloWorld_data\\.venv\\lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:99\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_process:\n\u001b[0;32m    101\u001b[0m     pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mstart_multi_process_pool()\n",
      "File \u001b[1;32mc:\\Users\\ohmyh\\OneDrive\\바탕 화면\\GitHub\\HelloWorld_data\\.venv\\lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:99\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m), texts))\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_process:\n\u001b[0;32m    101\u001b[0m     pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mstart_multi_process_pool()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Document' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "# \"\"\"\n",
    "# 런타임 모두 실행 시 DB에 데이터가 중복 저장되는 것을 막기 위해 주석 처리 해놨습니다.\n",
    "# 필요한 코드이니 지우지 말아주세요.\n",
    "# \"\"\"\n",
    "#DB에 텍스트 데이터 추가\n",
    "\n",
    "#꼭 확인!!\n",
    "index_name = 'helloworld4'\n",
    "\n",
    "db.from_texts(chunks, \n",
    "              embedding=hf,\n",
    "              es_cloud_id=ES_CLOUD_ID,\n",
    "              es_user=ES_USER,\n",
    "              es_password=ES_PASSWORD,\n",
    "              es_api_key=ES_API_KEY,\n",
    "              index_name=index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
